
# IEC 60601-2-57

# IEC 80002-1

## New standards
IEC 80001-1 [6] covers the integration of MEDICAL DEVICES into IT networks in a clinical environment.


## Introduction

Much of the TASK of software RISK MANAGEMENT consists of identifying those sequences of events that can lead to a HAZARDOUS SITUATION and identifying points in the sequences of events at which the sequence can be interrupted, preventing HARM or reducing its probability.
Software sequences of events which contribute to HAZARDOUS SITUATIONS may fall into two categories:
a) sequences of events representing unforeseen software responses to inputs (errors in specification of the software);
b) sequences of events arising from incorrect coding (errors in implementation of the software).

# General requirements for RISK MANAGEMENT

### 3.1.1 General

While software aspects of RISK MANAGEMENT can not be effectively performed in isolation from overall MEDICAL DEVICE RISK MANAGEMENT, there are activities that may be best performed by software engineers as an integral part of the software LIFE-CYCLE.

By participating in the MEDICAL DEVICE design PROCESS, the software engineer can contribute to SAFETY-related decisions concerning software-related RISKS as the design evolves. Such decisions should include but not be limited to:
- the provision of adequate hardware resources to support the software;
- the partitioning of functions between hardware and software;
- the intended use of the whole MEDICAL DEVICE and the intended use of the software user interfaces;
- the avoidance of unnecessarily complex software.

For example, during software development, Subclause 5.2.4 of IEC 62304:2006 requires the re-evaluation of the MEDICAL DEVICE RISK ASSESSMENT when software requirements are established. This re-evaluation may cause an update to SYSTEM requirement specifications and the MEDICAL DEVICE RISK ASSESSMENT. RISK EVALUATION should be repeated at all stages from requirements via ARCHITECTURE and design to the implementation of software.

All information related to the software needs to be up to date in order to avoid miscommunication between engineers. Proposals for software changes are examined for side-effects, especially side-effects which affect SAFETY. This may lead to repetition of parts of the RISK MANAGEMENT PROCESS.

### 3.1.4 Characteristics of safe SYSTEMS incorporating software

Highly desirable characteristics of safe SYSTEMS include:
– the use of simple hardware SAFETY mechanisms to avoid excessive demands on SAFETY- RELATED SOFTWARE ITEMS;
– the use of only very simple SAFETY-RELATED SOFTWARE ITEMS;
– the distribution of SAFETY-RELATED SOFTWARE ITEMS between a number of independent processors;
– sufficient hardware to run all SAFETY-RELATED SOFTWARE when needed and without contention;
– the use of a deterministic design of software timing;
– the appropriate handling of failure conditions, for example
    + warning the user of failures and to allow opportunities for informed intervention;
    + providing reduced functionality in failure conditions;
    + shutting down safely when possible in failure conditions;
    + recovering quickly from failures;
– the means of preventing software code from being modified in its execution environment either through self-modification or as the result of data input;
– the means of detecting and/or preventing corruption of SAFETY-related data.

### 3.3.3 Programming experience and attitude

It is particularly important to assign experienced staff to the following software TASKS:
– identification of the ways in which software can fail;
– analysis of RISKS associated with software failure;
– identification of RISK CONTROL measures;
– analysis of post-release PROBLEM REPORTS;
– design and implementation of changes, especially post-release.

## 3.4 RISK MANAGEMENT plan

### 3.4.1 General

The RISK MANAGEMENT plan should address the fact that software is part of the MEDICAL DEVICE by including:
– a description of the MEDICAL DEVICE including what functionality of the MEDICAL DEVICE will be implemented in software;
– a statement that software will be developed according to IEC 62304;
– a reference to software development aspects unique to software RISK MANAGEMENT (see Note);
– the RISK acceptance criteria for software-caused or software-controlled RISKS if they differ from acceptance criteria for other components of the MEDICAL DEVICE.


When planning the activities related to collection and review of relevant production and POST- PRODUCTION information the following specific aspects for software should be considered:
– If SOFTWARE OF UNKNOWN PROVENANCE (SOUP) is used, then actively monitoring and evaluating publicly available ANOMALY lists and information about the SOUP field performance should be planned. Where possible, this should be supported by a contractual agreement with the SOUP supplier at the time of SOUP acquisition. If the users of the MEDICAL DEVICE may (intentionally or not) modify the SOUP of the MEDICAL DEVICE on their own (e.g. SOUP patches or updates), then special care should be taken in monitoring the provision of new SOUP VERSIONS for the market. See also Clause 9 regarding SOUP and POST-PRODUCTION monitoring.
– The MANUFACTURER should make it possible for the originator of a complaint to identify and report the software VERSION.

### 3.4.3 Specific RISK-related topics of the software development plan according to IEC 62304 

When establishing the MEDICAL DEVICE RISK MANAGEMENT PROCESS, aspects unique to software RISK MANAGEMENT should be considered, such as safe coding standards, VERIFICATION methods (e.g. formal proofs, peer reviews, walk-throughs, simulations, etc), and use of syntactic and logic checkers. If such aspects are considered RISK CONTROL measures, then they would also be subject to VERIFICATION (see Table B.2 for examples of verifying RISK CONTROL measures).

## 4.2 INTENDED USE and identification of characteristics related to the SAFETY of the MEDICAL DEVICE

### 4.2.1 General

While this is not a software-specific concern, the use of software may lead to an increased RISK of misuse because:
– the MEDICAL DEVICE’s behaviour is more complex and therefore more difficult to master or understand;
– the user may become over-reliant on software, not understanding its limitations;
– the MEDICAL DEVICE may be configurable, and the user may be unaware of the current configuration.
– MEDICAL DEVICES may communicate with MEDICAL and non-MEDICAL DEVICES in a manner that cannot be anticipated in detail by the MEDICAL DEVICE MANUFACTURER.

### 4.2.3 MEDICAL DEVICE interconnection

It is therefore important for MANUFACTURERS to specify a limited set of INTENDED USES for the MEDICAL DEVICE’S communication interfaces and to design the interfaces as far as possible to limit interconnections and communications to those which are safe.

## 4.3 Identification of HAZARDS

Software may contribute to a HAZARDOUS SITUATION in several ways, including some of the following (see also Annex B):
– the software may correctly implement an unsafe SYSTEM requirement, leading to behaviour whose hazardous nature is not appreciated until actual HARM occurs;
– the software specification may incorrectly implement a SYSTEM requirement, leading to undesired behaviour that is correct according to the software specification;
– the software design and implementation may be faulty, leading to behaviour that is contrary to the software specification. Obvious faults might arise from misunderstanding of the software specification, and errors converting the specification into code. Less obvious faults could arise from unforeseen interactions between SOFTWARE ITEMS and between the software and its infrastructure, including hardware and the operating SYSTEM.

In a MEDICAL DEVICE incorporating software, careful and comprehensive HAZARD identification may lead (in later stages of the RISK MANAGEMENT PROCESS) to the following important outcomes:
– hardware RISK CONTROL measures that will prevent software from causing HARM;
– the removal of a potentially harmful software function from the software specification;
– RISK CONTROL measures that use software to prevent HARM (see Subclause 5.2.3 of IEC 62304:2006);
– identification of the parts of the software that must be implemented with low defect density and parts of the software specification which must be targeted for special testing (Subclause 4.3 of IEC 62304:2006);
– identification of higher SAFETY class SOFTWARE ITEMS that must be segregated from other SOFTWARE ITEMS (in a lower software SAFETY class) to prevent HARM arising from unexpected side-effects (see Subclauses 4.3 and 5.3.5 of IEC 62304:2006). See further discussion of this in 6.2.2.2.4.

### 4.4.2 Methods of identification

In view of the difficulty of anticipating which software defects will be present in each SOFTWARE ITEM, the starting point for FMEA would be to list the safety-related requirements of each SOFTWARE ITEM and consider the question: If this requirement is not met, what would be the consequences?

While it is difficult to anticipate exactly what may fail in a SOFTWARE ITEM, it is possible to identify categories of defects, each of which has well-known RISK CONTROL measures. MANUFACTURERS should maintain their own lists of categories of software defects relevant to their own products.

### 4.4.3 Probability

In many cases, estimating the probability of occurrence of HARM may not be possible, and the RISK should be evaluated on the basis of the SEVERITY of the HARM alone. RISK ESTIMATION in these cases should be focused on the SEVERITY of the HARM resulting from the HAZARDOUS SITUATION.

Although the probability of a HAZARDOUS SITUATION cannot be estimated either before or after the checksum is implemented, it can be asserted that the probability of a HAZARDOUS SITUATION after the checksum is in place is lower than it was before implementing the checksum. It is the responsibility of the MANUFACTURER to demonstrate that the RISK CONTROL measure is effective in meeting the acceptability criteria for RESIDUAL RISK that was identified in the RISK MANAGEMENT plan.

#### 6.2.1.2 Inherent SAFETY by design

In most cases, inherent SAFETY by design, applied to software, will involve:
– eliminating unnecessary features;
– changing the software ARCHITECTURE to avoid sequences of events that lead to HAZARDOUS SITUATIONS;
– simplifying the user interface to reduce the probability of human errors in use;
– specifying software design rules to avoid software ANOMALIES.
An example of the latter would include:
– using only static memory allocation to avoid software ANOMALIES related to dynamic memory allocation;
– using a restricted VERSION of a programming language to avoid structures which are likely to lead to programming errors.

#### 6.2.1.5 Which events need RISK CONTROL measures?

Obvious points at which RISK CONTROL measures may be applied include:
– inputs to the SOFTWARE SYSTEM as a whole;
– outputs from the SOFTWARE SYSTEM as a whole;
– internal interfaces between software modules.

A RISK CONTROL measure which limits the range of an input to the software can prevent unsafe outputs. Less obviously, it can also reduce the probability of the input leading to HARM due to an ANOMALY in the software, because it reduces the probability that the software will operate in unexpected ways that may not have been tested (see 4.4.3).


#### 6.2.2.2 RISK CONTROL measures and software architectural design

Software ARCHITECTURE should describe features of the software used to control RISK by inherently safe design, as well as software mechanisms for protective measures to reduce RISK.

If a SOFTWARE ITEM has a role in SAFETY, then RISK ASSESSMENT should address the following questions:
– Can the SAFETY-RELATED SOFTWARE ITEM gain access to its processor when needed?
– Can the SAFETY-RELATED SOFTWARE ITEM be guaranteed enough processor time to complete its TASK before an unsafe state develops into an accident?
– Can it be demonstrated that no other SOFTWARE ITEM can corrupt or otherwise interfere with the SAFETY-RELATED SOFTWARE ITEM?

Development methods should be chosen to make all of the above issues visible to the designer. For example, it is not enough to design a SAFETY-RELATED SOFTWARE ITEM as a PROCESS which, all being well, will run when the operating system gets around to it. The development method should support deliberate design of scheduling, priority and timing.

For example, a failure of a laboratory blood analyzer to provide a result may not in some cases be hazardous, but providing an incorrect result could be. In this example, shutting down the analyzer when defensive programming checks indicate unexpected faults, rather than continuing to operate, reduces RISKS. In a fail-safe ARCHITECTURE, a SYSTEM or component fault, or other hazardous condition, may lead to a loss of function, but in a manner that preserves the SAFETY of operators and patients. In a fail-operational SYSTEM, the SYSTEM may continue to operate safely, but with degraded performance (e.g. reduced capacity or slower response time).

#### 6.2.2.5 Risk control measures for software anomalies

RISK CONTROL measures can reduce the probability of HARM originating from software ANOMALIES. There will usually be places in the software ARCHITECTURE where a RISK CONTROL measure can reduce the probability of HARM irrespective of the nature of preceding events. If this is done carefully, it is not necessary to anticipate the exact nature of software ANOMALIES in order to prevent them from causing HARM.
In cases where this approach is not practicable, for example if a preventive measure is implemented in software, methods should be used to assure the integrity of the software

#### 6.2.2.6 Process as a risk control measure

The best solution in this case is inherent SAFETY by design, so that software ANOMALIES cannot result in a HAZARDOUS SITUATION.

When this is not possible, an effective software development PROCESS may be used to reduce the probability of occurrence of the software ANOMALIES. There is strong consensus that PROCESS RISK CONTROL measures are beneficial when considered in combination with other types of RISK CONTROL measures and if defined in detail.

When implementation of a rigorous development PROCESS is used to reduce RISK of HAZARDOUS SITUATIONS resulting from software ANOMALIES, the effectiveness of the RISK CONTROL measures should be demonstrated by collecting and analyzing data showing the frequency of failures resulting from software ANOMALIES. To support the claim that a PROCESS produces high-integrity software, there should be evidence that there are no or very infrequent software failures.


### 6.2.3 SOFTWARE OF UNKNOWN PROVENANCE (SOUP) considerations

Therefore the SYSTEM and software ARCHITECTURE should be designed to provide RISK CONTROL measures needed to monitor or isolate SOUP to prevent it from causing HAZARDS if it fails.

When SOUP is included in the MEDICAL DEVICE, care must be taken to prevent compromising MEDICAL DEVICE SAFETY. Such a situation may call for the introduction of “wrappers” or a middleware ARCHITECTURE. The middleware may:

a) prevent the use of features of the SOUP that one does not want to use,
b) perform logical checks to ensure correct information is transferred between the SOUP and the MEDICAL DEVICE SOFTWARE, or
c) provide additional information needed by the MEDICAL DEVICE.

## 6.3 Implementation of RISK CONTROL measure(s)

VERIFICATION that the RISK CONTROL measures have been properly implemented and are effective at controlling the RISK is essential for software. Both analysis and testing are likely to be necessary. Key aspects to consider include:
a) TRACEABILITY to assure that all SAFETY-RELATED SOFTWARE ITEMS are identified and all SAFETY-related functionality is specified, implemented, and tested in all relevant VERSIONS and variants (e.g. for different platforms, languages, or MEDICAL DEVICE models) of the software;
b) greater rigour and coverage when testing RISK CONTROL measures including testing under a wide range of abnormal and stress conditions;
c) focus on regression testing RISK CONTROL measures and SAFETY-related functionality when changes are made, even if the changes are not intended to affect SAFETY.

ANOMALIES with SAFETY consequences can be evaluated to determine if they were identified in the RISK ASSESSMENT and if identified RISK CONTROL measures would suffice for them once implemented.

## 6.4 RESIDUAL RISK EVALUATION

Given the difficulty in estimating the probability of software ANOMALIES, RESIDUAL RISK EVALUATION usually involves determining whether all sequences of events which lead to unacceptable RISK have RISK CONTROL measures to reduce the probability of their occurrence or to limit the SEVERITY of HARM to an acceptable level as defined in the RISK MANAGEMENT plan

# 9 Production and POST-PRODUCTION information

When establishing a system to collect and review information about the MEDICAL DEVICE, the MANUFACTURER should consider among other things:
a) the mechanisms by which information generated by the operator, the user, or those accountable for the installation, use and maintenance of the MEDICAL DEVICE is collected and processed;



























